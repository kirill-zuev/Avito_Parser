# Avito_Parser

Проект для парсинга объявлений с Avito с сохранением данных в PostgreSQL и возможностью визуализации через Superset.

---

## Установка и запуск

### 1. Установка зависимостей
Все основные зависимости находятся в файле:
```bash
pip install -r requirements.txt
````

### 2. Запуск Superset

Перейдите в папку с Superset и выполните:

```bash
bash reload.sh
```

> Если запускаете первый раз — в `reload.sh` есть последовательность закомментированных команд, которые необходимо выполнить.

### 3. Настройка PostgreSQL

Аналогично Superset: перейдите в папку и выполните `bash reload.sh`.
При первом запуске используйте закомментированные команды для инициализации.

### 4. Запуск парсера

Перейдите в папку `parser_avito` и запустите сервер:

```bash
python server.py
```

После этого можно отправлять запросы:

```
http://localhost:<port>/
```

---

## Структура проекта

* **`parser_avito/`**

  * `server.py` — запуск API для парсера.
  * `routers.py` — основной класс парсера:
    * `AvitoParser` — базовые методы работы со страницами Avito.
    * `ExtendedParser` — наследуется от `AvitoParser`, добавляет функции для взаимодействия с БД.
  * `loactor.py` — классы для поиска элементов на страницах Avito.
  * `utils.py` — вспомогательные утилиты:
    * `Validator.generate_avito` — генерация ссылок на несколько дней вперед.
  * `clean_proc` — удаление процессов при перезапуске парсера.

* **`database/`**
  API для работы с базой данных:

  * сбор базы данных координат мест;
  * поиск адресов в заданном радиусе.

* **`postgre.py`**
  Класс для взаимодействия с PostgreSQL:

  * `create_database`
  * `update_database`
  * `check_and_aduid`
  * `exist`

* **`proxy.txt`**
  Список прокси для работы парсера.

  > Количество прокси должно быть **не меньше количества дней** парсинга.

---

## Логика работы с прокси

В коде используется запуск процессов по дням в цикле:

```python
for item, proxy in zip(urls, proxy[:len(urls)]):
    url, n_days = item["url"], item["days"]
    logger.info(f"{url=} {n_days=}")
    days = date_ + timedelta(days=n_days)
    process = multiprocessing.Process(
        target=parse_url,
        args=(url, date_, today, fast, days, proxy)
    )
    process.start()
```

Таким образом, для корректной работы необходимо, чтобы:

* количество доступных прокси ≥ количеству дней в запросах.

---

## Итоги

* Парсер Avito работает через API (`server.py`).
* Данные сохраняются в PostgreSQL (`postgre.py`).
* Для визуализации используется Superset.
* Управление парсером — через `routers.py`, расширяемый класс `ExtendedParser`.
* Вспомогательные инструменты и валидации — в `utils.py`.

* Логика поиска элементов на страницах Avito — в `loactor.py`.
